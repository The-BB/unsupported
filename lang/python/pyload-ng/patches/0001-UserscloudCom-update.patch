From 4377f6b3d751cce0eef9acd777df25c76a2a5a73 Mon Sep 17 00:00:00 2001
From: GammaC0de <gammac0de@users.noreply.github.com>
Date: Sun, 17 Oct 2021 01:17:09 +0300
Subject: [PATCH 01/73] [UserscloudCom] update

---
 .../plugins/downloaders/UserscloudCom.py      | 60 ++-----------------
 1 file changed, 5 insertions(+), 55 deletions(-)

diff --git a/src/pyload/plugins/downloaders/UserscloudCom.py b/src/pyload/plugins/downloaders/UserscloudCom.py
index 238cff229..4438a5928 100644
--- a/src/pyload/plugins/downloaders/UserscloudCom.py
+++ b/src/pyload/plugins/downloaders/UserscloudCom.py
@@ -2,43 +2,13 @@
 
 import re
 
-from pyload.core.network.cookie_jar import CookieJar
-from pyload.core.network.exceptions import Abort
-from pyload.core.network.http.http_request import HTTPRequest
+from ..base.xfs_downloader import XFSDownloader
 
-from ..base.simple_downloader import SimpleDownloader
 
-
-class BIGHTTPRequest(HTTPRequest):
-    """
-    Overcome HTTPRequest's load() size limit to allow loading very big web pages by
-    overrding HTTPRequest's write() function.
-    """
-
-    # TODO: Add 'limit' parameter to HTTPRequest in v0.6.x
-    def __init__(self, cookies=None, options=None, limit=1_000_000):
-        self.limit = limit
-        super().__init__(cookies=cookies, options=options)
-
-    def write(self, buf):
-        """
-        writes response.
-        """
-        if self.limit and self.rep.tell() > self.limit or self.abort:
-            rep = self.getResponse()
-            if self.abort:
-                raise Abort
-            with open("response.dump", mode="wb") as fp:
-                fp.write(rep)
-            raise Exception("Loaded Url exceeded limit")
-
-        self.rep.write(buf)
-
-
-class UserscloudCom(SimpleDownloader):
+class UserscloudCom(XFSDownloader):
     __name__ = "UserscloudCom"
     __type__ = "downloader"
-    __version__ = "0.09"
+    __version__ = "0.10"
     __status__ = "testing"
 
     __pattern__ = r"https?://(?:www\.)?userscloud\.com/(?P<ID>\w{12})"
@@ -54,6 +24,8 @@ class UserscloudCom(SimpleDownloader):
     __license__ = "GPLv3"
     __authors__ = [("GammaC0de", "nitzo2001[AT]yahoo[DOT]com")]
 
+    PLUGIN_DOMAIN = "userscloud.com"
+
     INFO_PATTERN = r'<a href="https://userscloud.com/.+?" target="_blank">(?P<N>.+?) - (?P<S>[\d.,]+) (?P<U>[\w^_]+)</a>'
     OFFLINE_PATTERN = r"The file you are trying to download is no longer available"
     LINK_FREE_PATTERN = r'<a href="(https://\w+\.usercdn\.com.+?)"'
@@ -64,25 +36,3 @@ class UserscloudCom(SimpleDownloader):
         self.multi_dl = True
         self.resume_download = False
         self.chunk_limit = 1
-
-        try:
-            self.req.http.close()
-        except Exception:
-            pass
-
-        self.req.http = BIGHTTPRequest(
-            cookies=CookieJar(None),
-            options=self.pyload.request_factory.get_options(),
-            limit=300_000,
-        )
-
-    def handle_free(self, pyfile):
-        url, inputs = self.parse_html_form('name="F1"')
-        if not inputs:
-            return
-
-        self.data = self.load(pyfile.url, post=inputs)
-
-        m = re.search(self.LINK_FREE_PATTERN, self.data)
-        if m is not None:
-            self.link = m.group(1)
-- 
2.30.2

